{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BaseModule\n",
    "from utils import get_runs\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878e8f80452b4f108557210ddd8d785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset:', options=('Iris', 'synthetic'), value='Iris')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6916d388340e4118a408faa75d2e5b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('linear', 'MLP'), value='linear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8671543c64164c7e80c64eb563e95592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='# of epochs:', min=10, step=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382bcbdfa1d34ff1b260cb371ab3508a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Mode:', options=(('Hyperparameters', False), ('Test', True)), value=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize widget for notebook parameters\n",
    "dataset_name = widgets.Dropdown(\n",
    "    options=['Iris', 'synthetic'],\n",
    "    description='Dataset:'\n",
    ")\n",
    "model_name = widgets.Dropdown(\n",
    "    options=['linear', 'MLP'],\n",
    "    description='Model:'\n",
    ")\n",
    "num_epochs = widgets.IntSlider(\n",
    "    min=10,\n",
    "    max=100,\n",
    "    step=10,\n",
    "    description='# of epochs:',\n",
    "    orientation='horizontal',\n",
    ")\n",
    "test_mode = widgets.ToggleButtons(\n",
    "    options=[('Hyperparameters', False), ('Test', True)],\n",
    "    description='Mode:'\n",
    ")\n",
    "\n",
    "# display widgets\n",
    "display(dataset_name)\n",
    "display(model_name)\n",
    "display(num_epochs)\n",
    "display(test_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W&B parameters\n",
    "PROJECT = 'merck-training'\n",
    "CONFIG = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'batch_size': {'values': [64, 128]},\n",
    "        'learning_rate': {'values': [3e-3, 1e-3, 3e-4, 1e-4]}\n",
    "    }\n",
    "}\n",
    "\n",
    "SWEEP_PATHS = {\n",
    "    'Iris': {\n",
    "        'MLP': 'boctrl-c/merck-training/sweeps/z92u55iu',\n",
    "        'linear': 'boctrl-c/merck-training/sweeps/l7247jdg'\n",
    "    },\n",
    "    'synthetic': {\n",
    "        'MLP': 'boctrl-c/merck-training/sweeps/yak28k5i',\n",
    "        'linear': 'boctrl-c/merck-training/sweeps/req7e9fo'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1_t0</th>\n",
       "      <th>feature2_t0</th>\n",
       "      <th>feature3_t0</th>\n",
       "      <th>feature1_t1</th>\n",
       "      <th>feature2_t1</th>\n",
       "      <th>feature3_t1</th>\n",
       "      <th>feature1_t2</th>\n",
       "      <th>feature2_t2</th>\n",
       "      <th>feature3_t2</th>\n",
       "      <th>score_t0</th>\n",
       "      <th>score_t1</th>\n",
       "      <th>score_t2</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.275952</td>\n",
       "      <td>9.548464</td>\n",
       "      <td>20.857206</td>\n",
       "      <td>-1.640917</td>\n",
       "      <td>9.879204</td>\n",
       "      <td>19.796847</td>\n",
       "      <td>1.286034</td>\n",
       "      <td>7.853225</td>\n",
       "      <td>20.916851</td>\n",
       "      <td>-12.885027</td>\n",
       "      <td>-13.454494</td>\n",
       "      <td>-10.525529</td>\n",
       "      <td>-13.805164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.209974</td>\n",
       "      <td>11.657870</td>\n",
       "      <td>18.994037</td>\n",
       "      <td>-1.583167</td>\n",
       "      <td>11.185200</td>\n",
       "      <td>20.050245</td>\n",
       "      <td>-0.040625</td>\n",
       "      <td>10.566484</td>\n",
       "      <td>19.212929</td>\n",
       "      <td>-11.824399</td>\n",
       "      <td>-13.999659</td>\n",
       "      <td>-11.552003</td>\n",
       "      <td>-10.581159</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.928405</td>\n",
       "      <td>11.057740</td>\n",
       "      <td>22.520939</td>\n",
       "      <td>1.421343</td>\n",
       "      <td>11.178265</td>\n",
       "      <td>20.241026</td>\n",
       "      <td>-0.029118</td>\n",
       "      <td>10.790355</td>\n",
       "      <td>20.340290</td>\n",
       "      <td>-11.021825</td>\n",
       "      <td>-12.921086</td>\n",
       "      <td>-14.071246</td>\n",
       "      <td>-10.887280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583430</td>\n",
       "      <td>9.428129</td>\n",
       "      <td>19.557302</td>\n",
       "      <td>0.102584</td>\n",
       "      <td>9.106648</td>\n",
       "      <td>14.846111</td>\n",
       "      <td>-1.093920</td>\n",
       "      <td>10.778970</td>\n",
       "      <td>20.884420</td>\n",
       "      <td>-15.485350</td>\n",
       "      <td>-15.343734</td>\n",
       "      <td>-12.313570</td>\n",
       "      <td>-14.453414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142398</td>\n",
       "      <td>9.179987</td>\n",
       "      <td>20.252988</td>\n",
       "      <td>-1.483179</td>\n",
       "      <td>9.365358</td>\n",
       "      <td>19.794396</td>\n",
       "      <td>1.470028</td>\n",
       "      <td>12.056651</td>\n",
       "      <td>20.820639</td>\n",
       "      <td>-13.315184</td>\n",
       "      <td>-13.604042</td>\n",
       "      <td>-14.272901</td>\n",
       "      <td>-15.524159</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1_t0  feature2_t0  feature3_t0  feature1_t1  feature2_t1  \\\n",
       "0     1.275952     9.548464    20.857206    -1.640917     9.879204   \n",
       "1     2.209974    11.657870    18.994037    -1.583167    11.185200   \n",
       "2    -0.928405    11.057740    22.520939     1.421343    11.178265   \n",
       "3     0.583430     9.428129    19.557302     0.102584     9.106648   \n",
       "4     0.142398     9.179987    20.252988    -1.483179     9.365358   \n",
       "\n",
       "   feature3_t1  feature1_t2  feature2_t2  feature3_t2   score_t0   score_t1  \\\n",
       "0    19.796847     1.286034     7.853225    20.916851 -12.885027 -13.454494   \n",
       "1    20.050245    -0.040625    10.566484    19.212929 -11.824399 -13.999659   \n",
       "2    20.241026    -0.029118    10.790355    20.340290 -11.021825 -12.921086   \n",
       "3    14.846111    -1.093920    10.778970    20.884420 -15.485350 -15.343734   \n",
       "4    19.794396     1.470028    12.056651    20.820639 -13.315184 -13.604042   \n",
       "\n",
       "    score_t2      score  label  \n",
       "0 -10.525529 -13.805164    1.0  \n",
       "1 -11.552003 -10.581159    1.0  \n",
       "2 -14.071246 -10.887280    1.0  \n",
       "3 -12.313570 -14.453414    0.0  \n",
       "4 -14.272901 -15.524159    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 12, # of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "if dataset_name.value == 'Iris':\n",
    "    # Load the IRIS dataset\n",
    "    sklearn_data = load_iris()\n",
    "    data = pd.DataFrame(sklearn_data.data, columns=sklearn_data.feature_names)\n",
    "    data['species'] = pd.Categorical.from_codes(sklearn_data.target, sklearn_data.target_names)\n",
    "    display(data.head())\n",
    "    \n",
    "    X = data.iloc[:,:-1].to_numpy()\n",
    "    y = sklearn_data.target\n",
    "    \n",
    "if dataset_name.value == 'synthetic':\n",
    "    c_names = [\n",
    "        'feature1_t0',\n",
    "        'feature2_t0',\n",
    "        'feature3_t0',\n",
    "        'feature1_t1',\n",
    "        'feature2_t1',\n",
    "        'feature3_t1',\n",
    "        'feature1_t2',\n",
    "        'feature2_t2',\n",
    "        'feature3_t2',\n",
    "        'score_t0',\n",
    "        'score_t1',\n",
    "        'score_t2',\n",
    "        'score',\n",
    "        'label'\n",
    "    ]\n",
    "    data = pd.read_csv('data.csv', names=c_names, skiprows=1)\n",
    "    display(data.head())\n",
    "\n",
    "    X = data.iloc[:,:-2].to_numpy()\n",
    "    y = data.iloc[:,-1].to_numpy()\n",
    "\n",
    "num_features = X.shape[-1]\n",
    "num_classes = len(np.unique(y))\n",
    "print('# of features: {}, # of classes: {}'.format(num_features, num_classes))\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# to PyTorch tensors\n",
    "X_train = torch.tensor(X_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_train = torch.tensor(y_train).long()\n",
    "y_test = torch.tensor(y_test).long()\n",
    "\n",
    "# compute features' mean and std on the train split\n",
    "mean_train = X_train.mean(dim=0, keepdim=True)\n",
    "std_train = X_train.std(dim=0, keepdim=True)\n",
    "\n",
    "# normalize\n",
    "X_train = (X_train - mean_train)/std_train\n",
    "X_test = (X_test - mean_train)/std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 3760\n",
      "test set size: 940\n"
     ]
    }
   ],
   "source": [
    "# build PyTorch-compatible datasets from tensors\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "test_set = TensorDataset(X_test, y_test)\n",
    "\n",
    "if not test_mode.value:\n",
    "    dataset = train_set\n",
    "\n",
    "    # generate a validation split from the training set\n",
    "    train_set, val_set = random_split(dataset, [.8, .2],\n",
    "        generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "if not test_mode.value:\n",
    "    print('train set size: {}\\nval set size: {}\\ntest set size: {}'.format(\n",
    "        len(train_set),\n",
    "        len(val_set),\n",
    "        len(test_set)\n",
    "    ))\n",
    "if test_mode.value:\n",
    "    print('train set size: {}\\ntest set size: {}'.format(\n",
    "        len(train_set),\n",
    "        len(test_set)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/tommaso/miniconda3/envs/saint_env/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | model     | Sequential | 1.9 K \n",
      "1 | train_acc | Accuracy   | 0     \n",
      "2 | val_acc   | Accuracy   | 0     \n",
      "3 | test_acc  | Accuracy   | 0     \n",
      "-----------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "/home/tommaso/miniconda3/envs/saint_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/tommaso/miniconda3/envs/saint_env/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40940808de2543b0b1596a3cd0f552b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/tommaso/miniconda3/envs/saint_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:189: UserWarning: .test(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/tommaso/miniconda3/envs/saint_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c2306623514ba9af07bcb3db3c09fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6872340440750122\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# initialize the W&B sweep\n",
    "if not test_mode.value:\n",
    "    wandb.login()\n",
    "    sweep_id = wandb.sweep(CONFIG, project=PROJECT)\n",
    "\n",
    "def train():\n",
    "    \"\"\"Wraps the training process for W&B compatibility.\n",
    "    \"\"\"\n",
    "\n",
    "    if not test_mode.value:\n",
    "        run = wandb.init()\n",
    "        config = wandb.config\n",
    "        \n",
    "        # retrieve hyperparameters from the current sweep run\n",
    "        bs = config['batch_size']\n",
    "        lr = config['learning_rate']\n",
    "    \n",
    "    if test_mode.value:\n",
    "        df = get_runs(SWEEP_PATHS[dataset_name.value][model_name.value])\n",
    "        df = df.sort_values(['val_acc'], ascending=[False]).iloc[0]\n",
    "        \n",
    "        # retrieve best hyperparameters\n",
    "        bs = df['batch_size'].item()\n",
    "        lr = df['learning_rate'].item()\n",
    "\n",
    "    # initialize dataloaders\n",
    "    train_loader = DataLoader(train_set, batch_size=bs, shuffle=True)\n",
    "    if not test_mode.value: val_loader = DataLoader(val_set, batch_size=bs)\n",
    "    test_loader = DataLoader(test_set, batch_size=bs)\n",
    "\n",
    "    # initialize the model\n",
    "    if model_name.value == 'linear': # linear model\n",
    "        model = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    if model_name.value == 'MLP': # Multilayer perceptron (MLP)\n",
    "        model = nn.Sequential(\n",
    "        nn.Linear(num_features, 128), # layer of neurons\n",
    "        nn.ReLU(), # activation function\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    # Lightning wrapper\n",
    "    model = BaseModule(model, num_classes=num_classes, lr=lr)\n",
    "\n",
    "    if not test_mode.value:\n",
    "        trainer = Trainer(\n",
    "            max_epochs=num_epochs.value,\n",
    "            accelerator='gpu',\n",
    "            devices=[0],\n",
    "            logger=WandbLogger(),\n",
    "            log_every_n_steps=10,\n",
    "            default_root_dir='checkpoints'\n",
    "        )\n",
    "    if test_mode.value:\n",
    "        trainer = Trainer(\n",
    "            max_epochs=num_epochs.value,\n",
    "            accelerator='gpu',\n",
    "            devices=[0],\n",
    "            default_root_dir='checkpoints_test'\n",
    "        )\n",
    "\n",
    "    if not test_mode.value:\n",
    "        trainer.fit(model, train_loader, val_loader) # train and validate\n",
    "    if test_mode.value:\n",
    "        trainer.fit(model, train_loader) # train\n",
    "        trainer.test(dataloaders=test_loader, ckpt_path='last') # test\n",
    "\n",
    "    if not test_mode.value:\n",
    "        run.finish()\n",
    "\n",
    "# run\n",
    "if not test_mode.value: wandb.agent(sweep_id, function=train)\n",
    "if test_mode.value: train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saint_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
